---
title: "Introducing Substrate"
description: "Introducing Substrate, the API for modular AI"
date: 06-20-2024
image: "/launch-image.png"
---

<div>
    <img width={1020} height={510} src="/launch-image.png" alt="Introducing Substrate" />
</div>

Today, we're launching [Substrate](https://substrate.run). We're also announcing our $8M Series Seed led by [Lightspeed](https://lsvp.com/stories/substrate-building-compound-ai-systems/).

We believe the most robust and productive integrations of AI are when many inference runs are used in coordination with each other in a well-defined logical structure. This leads to more capable, more reliable, and more interpretable AI systems.

Most people building with AI already know this; So-called "agentic" processes are becoming the norm, along with using LLMs for structured JSON generation in more constrained logical flows. But unless you work for Google, the main barrier to realizing multi-step AI workloads in your application is an infrastructure one. Most developers are left either creating an unwieldy mess of chained API calls to multiple providers which requires slow round-trips and expensive one-off calls, or they are attempting to deploy their own infrastructure which—without massive investment—tends to result in systems that are resource inefficient and slow. 

We took a hard look at this state of affairs, and recognized how much it is stifling progress.

Building large multi-step AI workloads requires sophisticated high-performance tooling and infrastructure. Nobody wants to deal with more tooling and infrastructure… but everyone would benefit from simple, intuitive interfaces that abstract away a powerful system underneath if they are flexible enough to work in any domain.

No tooling, no infrastructure – just elegant abstractions.

Substrate is the first inference API optimized specifically for multi-step AI workloads. With Substrate, you connect nodes from a [curated library](https://docs.substrate.run/overview/api) that includes optimized ML models, built-in file and vector storage, a code interpreter, and logical control flow. By simply connecting nodes, you describe a graph program, which Substrate then analyzes and runs as fast as possible. Entire graphs of many nodes will often run on a single machine, with auto batching and microsecond communication between tasks.

We've been working on Substrate privately for nearly a year. We've battle-tested the product with great customers like [Substack](/substack), and we're finally ready to open access to everyone.

[Let us know](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA) what you think. We can't wait to see what you build.
